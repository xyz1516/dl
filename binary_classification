#Binary classification IMDB Dataset

import numpy as np
from tensorflow.keras.datasets import imdb
import matplotlib.pyplot as plt

#%%
# Load the dataset
(X_train,y_train),(X_test,y_test)=imdb.load_data()
X=np.concatenate((X_train,X_test),axis=0)
y=np.concatenate((y_train,y_test),axis=0)

#%%
# Summarize size
print("Training data:")
print(X.shape)
print(y.shape)

#%%
#Word Embedding
print(imdb.load_data(num_words=5000))

#%%
#Simple Multi-layer perceptron model for the IMDB Dataset
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing import sequence

#%%
#Truncate or pad the dataset to a length of 500 for each observation
X_train=sequence.pad_sequences(X_train,maxlen=500)
X_test=sequence.pad_sequences(X_test,maxlen=500)
Embedding(5000,32,input_length=500)

#%%

#load the dataset but only keep the top n words,zero the rest
top_words=5000
(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=top_words)

#%%
#Bound reviews at 500 words,truncating longer reviews and 0 padding shorter one 
max_words=500
X_train=sequence.pad_sequences(X_train,maxlen=max_words)
X_test=sequence.pad_sequences(X_test,maxlen=max_words)

#%%
#create the model
model=Sequential()
model.add(Embedding(top_words,32,input_length=max_words))
model.add(Flatten())
model.add (Dense(250,activation="relu"))
model.add(Dense(1,activation="sigmoid"))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

#%%
#Fit the model
model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=2,batch_size=128,verbose=2)

#%%
#Final evaluation of the model
scores=model.evaluate(X_test,y_test,verbose=0)
print("Accuracy:%.2f%%"%(scores[1]*100))










